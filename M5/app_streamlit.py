import os
import io
import json
import pickle
import time
import seaborn as sns
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Page config
st.set_page_config(page_title="–ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –±—É–¥—É—â–µ–µ –∞—Ç–æ–º–æ–≤... üî¨", layout="wide")

# Dark blue theme CSS (strong contrast)
st.markdown(
    """
    <style>
    .stApp { background: #061428; color: #e8f2ff; }
    .block-container {
        background: linear-gradient(180deg, #071833 0%, #0b2746 100%);
        border-radius: 12px;
        padding: 28px 32px;
        box-shadow: 0 6px 18px rgba(0,0,0,0.6);
    }
    h1, h2, h3, h4, h5, h6, p, label, span, div { color: #e6f1ff !important; }
    section[data-testid="stSidebar"] > div {
        background: linear-gradient(180deg,#061428 0%, #07192b 100%) !important;
        color: #dbeeff !important;
    }
    .stButton>button, .stDownloadButton>button {
        background-color: #0b3b76 !important;
        color: #ffffff !important;
        border-radius: 8px !important;
        border: 1px solid #2b66b0 !important;
        padding: 6px 12px !important;
    }
    .stButton>button:hover, .stDownloadButton>button:hover { background-color: #154f9e !important; }
    input, textarea, select, div[data-baseweb="select"] { background-color: #08203a !important; color: #e6f1ff !important; }
    .stDataFrame table { background-color: #071733 !important; color: #e6f1ff !important; }
    .streamlit-expanderHeader { background-color: rgba(15,54,106,0.6) !important; color: #eaf4ff !important; }
    .streamlit-expanderContent { background-color: #071f35 !important; color: #e6f1ff !important; }
    </style>
    """,
    unsafe_allow_html=True,
)

# -------------------- Preprocessing utils --------------------
def to_list(x):
    if isinstance(x, np.ndarray):
        return x.tolist()
    return x if isinstance(x, list) else []

def preprocess_data(df):
    df = df.copy()
    for col in ['positions', 'atomicNumbers', 'elements', 'gradient']:
        if col in df.columns:
            df[f'{col}_len'] = df[col].apply(lambda x: len(to_list(x)))
    if 'positions' in df.columns:
        def min_max_dist(pos):
            arr = np.array(to_list(pos))
            if arr.size == 0:
                return 0.0, 0.0
            dists = np.linalg.norm(arr, axis=1)
            return np.min(dists), np.max(dists)
        df[['min_dist_center', 'max_dist_center']] = df['positions'].apply(lambda x: pd.Series(min_max_dist(x)))
        def avg_pairwise_dist(pos):
            arr = np.array(to_list(pos))
            if len(arr) < 2:
                return 0.0
            return pdist(arr).mean()
        df['avg_dist_atoms'] = df['positions'].apply(avg_pairwise_dist)
    elements_of_interest = ['H', 'Li', 'C', 'O', 'F', 'P']
    if 'elements' in df.columns:
        for el in elements_of_interest:
            df[f'count_{el}'] = df['elements'].apply(lambda x: to_list(x).count(el))
    else:
        for el in elements_of_interest:
            df[f'count_{el}'] = 0
    def count_adjacent_bonds(elems, a, b):
        el_list = to_list(elems)
        count = 0
        for i in range(len(el_list) - 1):
            if (el_list[i] == a and el_list[i + 1] == b) or (el_list[i] == b and el_list[i + 1] == a):
                count += 1
        return count
    if 'elements' in df.columns:
        df['CŒûO'] = df['elements'].apply(lambda x: count_adjacent_bonds(x, 'C', 'O'))
        df['CŒûH'] = df['elements'].apply(lambda x: count_adjacent_bonds(x, 'C', 'H'))
        df['CŒûC'] = df['elements'].apply(lambda x: count_adjacent_bonds(x, 'C', 'C'))
    else:
        df['CŒûO'] = df['CŒûH'] = df['CŒûC'] = 0
    if 'gradient' in df.columns:
        def max_grad_norm(grad):
            arr = np.array(to_list(grad))
            if arr.size == 0:
                return 0.0
            norms = np.linalg.norm(arr, axis=1)
            return np.max(norms)
        df['max_gradient'] = df['gradient'].apply(max_grad_norm)
    else:
        df['max_gradient'] = 0
    if 'dipoleMoment' in df.columns:
        def dipole_norm(dvec):
            d = np.array(to_list(dvec))
            return np.linalg.norm(d) if d.size == 3 else 0.0
        df['dipole_magnitude'] = df['dipoleMoment'].apply(dipole_norm)
    else:
        df['dipole_magnitude'] = 0
    cols_to_drop = ['positions', 'atomicNumbers', 'elements', 'gradient', 'dipoleMoment']
    df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True)
    return df

def prepare_data(input_data: pd.DataFrame) -> (pd.DataFrame, dict):
    if not isinstance(input_data, pd.DataFrame):
        raise TypeError("input_data –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å pd.DataFrame")
    df = input_data.copy()
    if 'positions' not in df.columns:
        raise ValueError("–°—Ç–æ–ª–±–µ—Ü 'positions' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –Ω–∞–±–æ—Ä–µ")
    reasons = {'no_positions': 0, 'totalEnergy': 0, 'charge': 0}
    start_n = df.shape[0]
    mask_positions = df['positions'].notna()
    reasons['no_positions'] = (~mask_positions).sum()
    df = df[mask_positions].copy()
    if 'totalEnergy' in df.columns:
        mask_e = df['totalEnergy'] < 1000
        reasons['totalEnergy'] = (~mask_e).sum()
        df = df[mask_e]
    if 'charge' in df.columns:
        mask_c = df['charge'] <= 10
        reasons['charge'] = (~mask_c).sum()
        df = df[mask_c]
    df = preprocess_data(df)
    redundant = ['atomicNumbers_len', 'elements_len', 'gradient_len', 'dipoleMoment_len', 'multiplicity']
    df.drop(columns=[c for c in redundant if c in df.columns], inplace=True)
    df = df.select_dtypes(include=[np.number])
    df.fillna(0.0, inplace=True)
    end_n = df.shape[0]
    reasons['total_removed'] = start_n - end_n
    return df, reasons

def safe_preview_dataframe(df: pd.DataFrame, n=5, max_chars=250):
    df_head = df.head(n).copy()
    heavy_examples = {}
    for col in df_head.columns:
        if df_head[col].dtype == 'object':
            def to_str(x):
                try:
                    if x is None:
                        s = "None"
                    else:
                        s = json.dumps(x, default=str, ensure_ascii=False)
                except Exception:
                    try:
                        s = str(x)
                    except Exception:
                        s = "<unserializable>"
                if len(s) > max_chars:
                    s = s[:max_chars] + "..."
                return s
            examples = [to_str(v) for v in df_head[col].tolist()]
            heavy_examples[col] = examples
            df_head[col] = df_head[col].apply(to_str)
    df_head.columns = [str(c) for c in df_head.columns]
    return df_head, heavy_examples

# session state init
if 'datasets' not in st.session_state:
    st.session_state.datasets = {}
if 'processed' not in st.session_state:
    st.session_state.processed = {}
if 'predictions' not in st.session_state:
    st.session_state.predictions = {}
if 'hide_easter' not in st.session_state:
    st.session_state.hide_easter = False

# Helper: show author info safely (modal if available, else expander)
def show_author_info():
    content = {
        "–ê–≤—Ç–æ—Ä": "Nika Denisenko",
        "–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ": "–°–¢–£–î-–ò–¢ 2025",
        "–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏": "–†–¢–£ –ú–ò–†–≠–ê",
        "–í–µ—Ä—Å–∏—è –ü–û": "P0-1 ‚Äî –ê–ª—å—Ñ–∞"
    }
    if hasattr(st, "modal"):
        try:
            with st.modal("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ"):
                st.markdown("### –û–± –∞–≤—Ç–æ—Ä–µ –∏ –ø—Ä–æ–µ–∫—Ç–µ")
                for k, v in content.items():
                    st.markdown(f"**{k}:** {v}")
                return
        except Exception:
            pass
    # fallback
    with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ"):
        st.markdown("### –û–± –∞–≤—Ç–æ—Ä–µ –∏ –ø—Ä–æ–µ–∫—Ç–µ")
        for k, v in content.items():
            st.markdown(f"**{k}:** {v}")

# Sidebar
with st.sidebar:
    if os.path.exists('logo.png'):
        st.image('logo.png', width=140)
    else:
        st.image('https://raw.githubusercontent.com/ageron/handson-ml2/master/images/hands_on_ml.png', width=140)
    st.markdown("## –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    st.markdown("---")
    local_files = [f for f in os.listdir('.') if f.lower().endswith(('.pickle', '.pkl', '.csv'))]
    for fname in local_files:
        if fname not in st.session_state.datasets:
            try:
                if fname.lower().endswith('.csv'):
                    df = pd.read_csv(fname)
                else:
                    df = pd.read_pickle(fname)
                st.session_state.datasets[fname] = df
            except Exception:
                pass
    dataset_names = ['--'] + list(st.session_state.datasets.keys())
    chosen_dataset = st.selectbox("–í—ã–±—Ä–∞—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö", options=dataset_names, index=0)
    st.markdown("---")
    uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å .pickle / .pkl / .csv", type=['pickle', 'pkl', 'csv'], accept_multiple_files=False)
    if uploaded is not None:
        try:
            uploaded.seek(0)
            if uploaded.name.lower().endswith('.csv'):
                df_up = pd.read_csv(uploaded)
            else:
                uploaded.seek(0)
                df_up = pickle.load(uploaded)
            name = uploaded.name
            st.session_state.datasets[name] = df_up
            st.success(f"–§–∞–π–ª '{name}' –∑–∞–≥—Ä—É–∂–µ–Ω –≤ —Å–µ—Å—Å–∏—é")
            chosen_dataset = name
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª: {e}")
    st.markdown("---")
    # ONLY models from disk (no builtins)
    models_on_disk = []
    if os.path.exists('models'):
        models_on_disk = [f.replace('.pkl', '') for f in os.listdir('models') if f.endswith('.pkl')]
    models_all = ['--'] + models_on_disk
    chosen_model = st.selectbox("–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å", options=models_all, index=0)
    st.markdown("---")
    st.write("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: \n1) –í—ã–±–µ—Ä–∏/–∑–∞–≥—Ä—É–∑–∏ –¥–∞—Ç–∞—Å–µ—Ç ‚Üí 2) –ù–∞–∂–º–∏ '–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å' ‚Üí 3) –í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å ‚Üí 4) '–°–æ–∑–¥–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è'.")
    st.markdown("---")
    if st.button('–û–± –∞–≤—Ç–æ—Ä–µ'):
        show_author_info()
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    instr_pdf = '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.pdf'

    if os.path.exists(instr_pdf):
        with open(instr_pdf, "rb") as f:
            pdf_bytes = f.read()
        
        st.download_button(
            label="–û—Ç–∫—Ä—ã—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (PDF)",
            data=pdf_bytes,
            file_name=instr_pdf,
            mime="application/pdf"
        )
    else:
        st.warning("–§–∞–π–ª –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.pdf' –Ω–µ –Ω–∞–π–¥–µ–Ω.")


# Main
st.title("–ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –±—É–¥—É—â–µ–µ –∞—Ç–æ–º–æ–≤...")
col1, col2 = st.columns([2, 3])

with col1:
    st.header("–î–∞—Ç–∞—Å–µ—Ç")
    st.write("–í—ã–±—Ä–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä:", chosen_dataset)
    if chosen_dataset != '--' and chosen_dataset in st.session_state.datasets:
        raw_df = st.session_state.datasets[chosen_dataset]
        try:
            preview_df, heavy_examples = safe_preview_dataframe(raw_df, n=5)
            st.dataframe(preview_df)
            if heavy_examples:
                st.markdown("**–í–ª–æ–∂–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ø—Ä–∏–º–µ—Ä—ã)**")
                for col, examples in heavy_examples.items():
                    with st.expander(f"{col} ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã"):
                        for i, ex in enumerate(examples):
                            st.write(f"{i}: ", ex)
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å preview: {e}")
            try:
                st.write(str(raw_df.head(5)))
            except Exception:
                st.write("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å preview ‚Äî –ø—Ä–æ–≤–µ—Ä—å –¥–∞—Ç–∞—Å–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ.")
    else:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
    can_preprocess = (chosen_dataset != '--') and (chosen_dataset in st.session_state.datasets)
    if st.button("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–±–æ—Ä", disabled=not can_preprocess):
        try:
            raw = st.session_state.datasets[chosen_dataset]
            raw_count = raw.shape[0]
            if os.path.exists('loading.gif'):
                st.image('loading.gif', caption='–ò–¥—ë—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Äî –ø–æ–¥–æ–∂–¥–∏—Ç–µ...', use_column_width=False)
                time.sleep(4)
            else:
                with st.spinner('–ò–¥—ë—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (—Å–∏–º—É–ª—è—Ü–∏—è 4 —Å–µ–∫)...'):
                    time.sleep(4)
            processed, reasons = prepare_data(raw)
            processed_count = processed.shape[0]
            removed_count = reasons.get('total_removed', raw_count - processed_count)
            removed_pct = (removed_count / raw_count * 100) if raw_count > 0 else 0.0
            st.session_state.processed[chosen_dataset] = processed
            st.success("–î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            st.info(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {raw_count} ‚Äî –ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {processed_count} ‚Äî –£–¥–∞–ª–µ–Ω–æ: {removed_count} ({removed_pct:.2f}%)")
            with st.expander('–î–µ—Ç–∞–ª–∏ –æ—á–∏—Å—Ç–∫–∏'):
                st.write(reasons)
            if removed_count > 0:
                try:
                    removed_idx = raw.index.difference(processed.index)
                    with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (–¥–æ 5)"):
                        st.write(raw.loc[removed_idx].head(5))
                except Exception:
                    st.write("–ù–µ–ª—å–∑—è –ø–æ–∫–∞–∑–∞—Ç—å —É–¥–∞–ª—ë–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã, –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏).")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    if chosen_dataset in st.session_state.processed:
        st.markdown("**–ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:**")
        st.write(list(st.session_state.processed[chosen_dataset].columns))

with col2:
    st.header("–ú–æ–¥–µ–ª—å –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    st.write("–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:", chosen_model)
    loaded_model = None
    if chosen_model != '--':
        model_path = os.path.join('models', chosen_model + '.pkl')
        if os.path.exists(model_path):
            try:
                with open(model_path, 'rb') as f:
                    loaded_model = pickle.load(f)
                st.success(f"–ú–æ–¥–µ–ª—å '{chosen_model}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
    predict_ready = (chosen_dataset in st.session_state.processed) and (chosen_model != '--')
    if st.button("–°–æ–∑–¥–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", disabled=not predict_ready):
        try:
            X = st.session_state.processed[chosen_dataset]
            # Use a fallback simple model if no saved model selected
            if loaded_model is None:
                m = LinearRegression()
                m.fit(X, np.zeros(X.shape[0]))
                preds = m.predict(X)
            else:
                preds = loaded_model.predict(X)
            preds_series = pd.Series(preds, index=X.index, name='prediction')
            st.session_state.predictions[(chosen_dataset, chosen_model)] = preds_series
            st.success("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ–∑–¥–∞–Ω—ã")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {e}")

    key = (chosen_dataset, chosen_model)
    if key in st.session_state.predictions:
        preds = st.session_state.predictions[key]
        df_show = pd.DataFrame({'prediction': preds})
        st.subheader("–¢–∞–±–ª–∏—Ü–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        st.dataframe(df_show.head(200))
        csv = df_show.to_csv(index=True).encode('utf-8')
        st.download_button("–°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (CSV)", data=csv, file_name=f"preds_{chosen_dataset}_{chosen_model}.csv")
        st.subheader("–ü—Ä–æ—Å–º–æ—Ç—Ä –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∏–Ω–¥–µ–∫—Å—É")
        idx_options = ['--'] + [str(i) for i in df_show.index[:500]]
        sel_index = st.selectbox("–í—ã–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å", options=idx_options)
        if sel_index != '--':
            try:
                sel_index_int = int(sel_index)
                val = preds.loc[sel_index_int]
                uncertainty = abs(0.05 * val) + 0.01
                st.write(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {val:.6f} ¬± {uncertainty:.6f}")
            except Exception as e:
                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")

# Graphs (white background for plots, sanitize data)
# Graphs
st.markdown("---")
st.header("–ì—Ä–∞—Ñ–∏–∫–∏ –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")

key = (chosen_dataset, chosen_model)
if key in st.session_state.predictions:
    X = st.session_state.processed[chosen_dataset]
    preds = st.session_state.predictions[key]

    st.subheader("–ì—Ä–∞—Ñ–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")

    feature_list = ['index'] + list(X.columns)
    feature = st.selectbox("–ü—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –æ—Å–∏ X", options=feature_list)
    plot_type = st.selectbox(
        "–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞",
        options=['–õ–∏–Ω–µ–π–Ω—ã–π', '–¢–æ—á–µ—á–Ω—ã–π', '–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞', '–°–∫—Ä–∏–ø–∏—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞']
    )

    fig, ax = plt.subplots(figsize=(8, 4))
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    ax.tick_params(colors='black', labelcolor='black')
    ax.xaxis.label.set_color('black')
    ax.yaxis.label.set_color('black')
    ax.grid(True, linestyle='--', alpha=0.4)

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
    x = np.array(preds.index) if feature == 'index' else np.array(X[feature])
    y = np.array(preds)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è NaN/Inf
    finite_mask = np.isfinite(y)
    if feature != 'index':
        finite_mask &= np.isfinite(x)
    x_clean = x[finite_mask]
    y_clean = y[finite_mask]

    if len(y_clean) == 0:
        st.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ (NaN/Inf).")
    else:
        if plot_type == '–õ–∏–Ω–µ–π–Ω—ã–π':
            ax.plot(x_clean, y_clean, color='#0b3b76', linewidth=1.2)  # —Ç–æ–Ω–∫–∞—è –ª–∏–Ω–∏—è
            ax.set_xlabel(feature)
            ax.set_ylabel('prediction')
        elif plot_type == '–¢–æ—á–µ—á–Ω—ã–π':
            ax.scatter(x_clean, y_clean, s=20, color='#154f9e', alpha=0.6)
            ax.set_xlabel(feature)
            ax.set_ylabel('prediction')
        elif plot_type == '–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞':
            ax.hist(y_clean, bins=40, color='#2b6fd6', alpha=0.7)
            ax.set_xlabel('prediction')
            ax.set_ylabel('count')
        elif plot_type == '–°–∫—Ä–∏–ø–∏—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞':
            sns.violinplot(y=y_clean, ax=ax, inner='quartile', color='#2b6fd6')
            ax.set_xlabel(feature)
            ax.set_ylabel('prediction')

        st.pyplot(fig)

    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    st.subheader("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    if not X.empty:
        corr = X.corr()
        fig_corr, ax_corr = plt.subplots(figsize=(10, 8))  # —É–≤–µ–ª–∏—á–∏–ª–∏ —Ä–∞–∑–º–µ—Ä
        sns.heatmap(
            corr,
            annot=True,
            fmt=".2f",
            cmap="coolwarm",
            ax=ax_corr,
            cbar=True,
            annot_kws={"size": 8}  # —É–º–µ–Ω—å—à–∏–ª–∏ —à—Ä–∏—Ñ—Ç —á–∏—Å–µ–ª
        )
        ax_corr.set_title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏", fontsize=12)
        st.pyplot(fig_corr)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã.")

    


# Easter
st.markdown("---")
if not st.session_state.get('hide_easter', False):
    if st.button('–ü–æ–∫–∞–∑–∞—Ç—å –ø–∞—Å—Ö–∞–ª–∫—É'):
        st.balloons()
        st.snow()

st.caption("–í–µ—Ä—Å–∏—è - 1. –ê–≤—Ç–æ—Ä: Nika Denisenko; –°–¢–£–î-–ò–¢ 2025; –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ –†–¢–£ –ú–ò–†–≠–ê")


